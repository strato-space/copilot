const constants = require("../../constants");
const ObjectId = require("mongodb").ObjectId;
const _ = require("lodash");
const axios = require('axios');
const { toFile } = require("openai");
const fileType = require('file-type');
const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');
const os = require('os');
const { v4: uuidv4 } = require('uuid');
const { getAudioBuffer, getAudioDuration } = require('../../utils/audio_utils');
const { send_message_update_event, send_session_update_event } = require("../bot_utils");
const { buildSegmentsFromChunks, resolveMessageDurationSeconds } = require("../../services/transcriptionTimeline");
const { mergeWithRuntimeFilter, recordMatchesRuntime } = require("../../services/runtimeScope");

// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
const CHUNKS_DIR = path.join(os.tmpdir(), 'voice_chunks');
const SEGMENT_TIME = 3 * 60; // –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (3 –º–∏–Ω—É—Ç—ã)
const HARD_MAX_TRANSCRIBE_ATTEMPTS = 10;
const TRANSCRIBE_RETRY_BASE_DELAY_MS = 60 * 1000;
const TRANSCRIBE_RETRY_MAX_DELAY_MS = 30 * 60 * 1000;
const INSUFFICIENT_QUOTA_RETRY = "insufficient_quota";
const OPENAI_KEY_ENV_NAMES = [
    "OPENAI_API_KEY",
];

const maskOpenAIKey = (apiKey) => {
    const raw = String(apiKey || "");
    if (!raw) return "unknown";

    const match = raw.match(/^sk-[A-Za-z0-9_-]{4}([A-Za-z0-9_-]*)([A-Za-z0-9_-]{4})$/);
    if (match) {
        return `sk-${match[1] ? match[1].slice(0, 4) : ""}...${match[2]}`;
    }

    if (raw.length <= 12) return raw;
    return `${raw.slice(0, 4)}...${raw.slice(-4)}`;
};

const getOpenAIKeySource = () => OPENAI_KEY_ENV_NAMES.find((name) => Boolean(process.env[name])) || "OPENAI_API_KEY";

const getOpenAIKeyDiagnostic = (openaiClient) => {
    const source = getOpenAIKeySource();
    const apiKey = openaiClient?.apiKey || process.env[source] || "";

    return {
        openai_key_source: source,
        openai_key_mask: maskOpenAIKey(apiKey),
        openai_key_present: Boolean(apiKey),
        openai_api_key_env_file: process.env.DOTENV_CONFIG_PATH || ".env",
    };
};

const getTranscriptionErrorContext = ({
    openaiClient,
    filePath = null,
    extra = {},
}) => ({
    server_name: constants.RUNTIME_SERVER_NAME || "unknown",
    ...getOpenAIKeyDiagnostic(openaiClient),
    ...(filePath ? { file_path: filePath } : {}),
    ...extra,
});

const getErrorMessage = (error) => {
    if (!error) return "Unknown transcription error";
    if (typeof error === "string") return error;
    if (error.response?.data?.error?.message) return error.response.data.error.message;
    if (error.message) return error.message;
    try {
        return JSON.stringify(error);
    } catch (stringifyError) {
        return String(error);
    }
};

const normalizeErrorCode = (error) => {
    if (!error) return null;
    const candidates = [
        error?.code,
        error?.error?.code,
        error?.response?.data?.error?.code,
        error?.response?.data?.error?.type,
        error?.error?.type,
    ];

    for (const candidate of candidates) {
        if (typeof candidate === "string" && candidate.trim()) {
            return candidate.trim().toLowerCase();
        }
    }

    return null;
};

const isQuotaError = (error) => {
    const status = Number(_.get(error, "status", _.get(error, "response.status", _.get(error, "response.data.status"))));
    const code = normalizeErrorCode(error) || "";
    const message = String(_.get(error, "message", _.get(error, "response.data.error.message", "") || "")).toLowerCase();

    if (status === 429) {
        if (/insufficient|quota|balance|billing|payment/.test(code)) return true;
        if (/insufficient[_\s-]*quota|exceeded your quota|quota.*exceeded|billing|payment required/.test(message)) return true;
    }

    return false;
};

const getRetryDelayMs = (attempts) => {
    const safeAttempts = Math.max(1, Number(attempts) || 1);
    const delay = TRANSCRIBE_RETRY_BASE_DELAY_MS * Math.pow(2, safeAttempts - 1);
    return Math.min(delay, TRANSCRIBE_RETRY_MAX_DELAY_MS);
};

const maskTelegramFileLink = (link) => {
    try {
        const str = link?.toString ? link.toString() : String(link || "");
        // Telegram file links often contain bot token in the URL path:
        // https://api.telegram.org/file/bot<TOKEN>/<file_path>
        return str.replace(/(\/file\/bot)[^/]+(\/)/, '$1***$2');
    } catch (e) {
        return "[unprintable link]";
    }
};

// –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞–ø–∫–∏ —Å —á–∞–Ω–∫–∞–º–∏
function cleanChunksFolder(chunksPath = CHUNKS_DIR) {
    if (!fs.existsSync(chunksPath)) {
        fs.mkdirSync(chunksPath, { recursive: true });
        return;
    }
    fs.readdirSync(chunksPath).forEach(file => {
        if (file.endsWith('.wav') || file.endsWith('.wav.error') || file.endsWith('.ogg') || file.endsWith('.mp3')) {
            fs.unlinkSync(path.join(chunksPath, file));
        }
    });
}

// –ö–ª–∞—Å—Å –¥–ª—è FFmpeg —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
class VoiceBotSegmentProcessor {
    constructor(sessionId, messageId, db, logger, openaiClient, baseTimestampMs) {
        this.sessionId = sessionId;
        this.messageId = messageId;
        this.db = db;
        this.logger = logger;
        this.openaiClient = openaiClient;
        this.baseTimestampMs = Number.isFinite(baseTimestampMs) ? baseTimestampMs : null;
        this.segmentDir = path.join(CHUNKS_DIR, `voice_${sessionId}_${messageId}_${uuidv4()}`);
        cleanChunksFolder(this.segmentDir);
        this.segmentPattern = `segment_%03d.wav`;
        this.transcriptionChunks = [];
        this.hasErrors = false;
        this.error = null;
    }

    cleanupSegmentsFolder() {
        if (this.hasErrors) return;
        try {
            fs.rmSync(this.segmentDir, { recursive: true, force: true });
        } catch (err) {
            this.logger.warn('–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É —Å–µ–≥–º–µ–Ω—Ç–æ–≤:', err?.message || err);
        }
    }

    async processStreamWithSegments(fileLink) {
        return new Promise((resolve, reject) => {
            try {
                this.logger.info('üé¨ –ó–∞–ø—É—Å–∫–∞–µ–º FFmpeg —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é —á–µ—Ä–µ–∑ HTTP...');
                this.logger.info('üì° –°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª:', maskTelegramFileLink(fileLink));

                const outputPattern = path.join(this.segmentDir, this.segmentPattern);
                this.logger.info('üìÅ –ü–∞—Ç—Ç–µ—Ä–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:', outputPattern);

                // FFmpeg —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π
                const ffmpeg = spawn('ffmpeg', [
                    '-i', fileLink,                          // HTTP-—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
                    '-f', 'segment',                         // –§–æ—Ä–º–∞—Ç: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
                    '-segment_time', SEGMENT_TIME.toString(), // –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞
                    '-segment_format', 'wav',                // –§–æ—Ä–º–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    '-c:a', 'pcm_s16le',                    // –ê—É–¥–∏–æ –∫–æ–¥–µ–∫
                    '-ar', '16000',                         // –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
                    '-ac', '1',                             // –ú–æ–Ω–æ
                    '-y',                                   // –ü–µ—Ä–µ–∑–∞–ø–∏—Å—å —Ñ–∞–π–ª–æ–≤
                    outputPattern                           // –ü–∞—Ç—Ç–µ—Ä–Ω –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
                ]);

                let segmentCounter = 0;
                let isProcessing = true;
                let processingSegments = new Set(); // –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∫–∞–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è

                // –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                const segmentWatcher = setInterval(() => {
                    if (!isProcessing) return;

                    const newSegments = this.findNewSegments(segmentCounter);

                    for (const segmentPath of newSegments) {
                        const segmentIndex = this.extractSegmentIndex(segmentPath);

                        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–µ–≥–º–µ–Ω—Ç –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
                        if (!processingSegments.has(segmentIndex)) {
                            processingSegments.add(segmentIndex);
                            this.logger.info(`üì¶ –ù–∞–π–¥–µ–Ω –Ω–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç: ${segmentPath} (–∏–Ω–¥–µ–∫—Å: ${segmentIndex})`);

                            // –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                            this.transcribeSegmentAsync(segmentPath, segmentIndex)
                                .finally(() => {
                                    processingSegments.delete(segmentIndex);
                                });

                            segmentCounter = Math.max(segmentCounter, segmentIndex + 1);
                        }
                    }
                }, 1000); // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É

                ffmpeg.stderr.on('data', (data) => {
                    const output = data.toString();
                    if (output.includes('Error') || output.includes('error')) {
                        this.logger.error('‚ùå FFmpeg error:', output);
                    }
                });

                ffmpeg.on('close', (code) => {
                    isProcessing = false;
                    clearInterval(segmentWatcher);

                    this.logger.info(`üèÅ FFmpeg –∑–∞–≤–µ—Ä—à–µ–Ω —Å –∫–æ–¥–æ–º: ${code}`);
                    if (code !== 0) {
                        this.hasErrors = true;
                        if (!this.error) {
                            this.error = new Error(`FFmpeg exited with code ${code}`);
                        }
                    }

                    // –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–µ–≥–º–µ–Ω—Ç—ã
                    const finalSegments = this.findNewSegments(0); // –ò—â–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã

                    for (const segmentPath of finalSegments) {
                        const segmentIndex = this.extractSegmentIndex(segmentPath);

                        if (!processingSegments.has(segmentIndex)) {
                            processingSegments.add(segmentIndex);
                            this.logger.info(`üì¶ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç: ${segmentPath} (–∏–Ω–¥–µ–∫—Å: ${segmentIndex})`);

                            this.transcribeSegmentAsync(segmentPath, segmentIndex)
                                .finally(() => {
                                    processingSegments.delete(segmentIndex);
                                });
                        }
                    }

                    // –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
                    const waitForCompletion = setInterval(async () => {
                        if (processingSegments.size === 0) {
                            clearInterval(waitForCompletion);

                            // –ñ–¥–µ–º –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏
                            setTimeout(async () => {
                                await this.saveTranscriptionChunks();
                                this.cleanupSegmentsFolder();
                                resolve({
                                    message: 'FFmpeg —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞',
                                    totalSegments: segmentCounter,
                                    transcriptionChunks: this.transcriptionChunks
                                });
                            }, 2000);
                        }
                    }, 500);
                });

                ffmpeg.on('error', (err) => {
                    isProcessing = false;
                    clearInterval(segmentWatcher);
                    this.logger.error('‚ùå –û—à–∏–±–∫–∞ FFmpeg:', err);
                    this.hasErrors = true;
                    if (!this.error) this.error = err;
                    reject(err);
                });

            } catch (error) {
                this.logger.error('‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FFmpeg —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:', error);
                this.hasErrors = true;
                if (!this.error) this.error = error;
                reject(error);
            }
        });
    }

    extractSegmentIndex(segmentPath) {
        const fileName = path.basename(segmentPath);
        const match = fileName.match(/segment_(\d{3})\.wav$/);
        return match ? parseInt(match[1]) : -1;
    }

    findNewSegments(minIndex) {
        const newSegments = [];

        try {
            // –ò—â–µ–º —Ñ–∞–π–ª—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
            const files = fs.readdirSync(this.segmentDir);
            const segmentRegex = /segment_(\d{3})\.wav$/;

            files.forEach(file => {
                const match = file.match(segmentRegex);
                if (match) {
                    const segmentIndex = parseInt(match[1]);
                    if (segmentIndex >= minIndex) {
                        const fullPath = path.join(this.segmentDir, file);

                        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                        try {
                            const stats = fs.statSync(fullPath);
                            if (stats.size > 1000) { // –ú–∏–Ω–∏–º—É–º 1KB
                                newSegments.push(fullPath);
                            }
                        } catch (err) {
                            // –§–∞–π–ª –µ—â–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è
                        }
                    }
                }
            });

        } catch (err) {
            this.logger.error('–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:', err);
        }

        return newSegments.sort(); // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏
    }

    async transcribeSegmentAsync(segmentPath, segmentIndex) {
        try {
            // –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ, —á—Ç–æ–±—ã —Ñ–∞–π–ª —Ç–æ—á–Ω–æ –∑–∞–ø–∏—Å–∞–ª—Å—è
            await new Promise(resolve => setTimeout(resolve, 500));

            this.logger.info(`üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç ${segmentIndex}...`);

            const audioFile = await toFile(fs.createReadStream(segmentPath), path.basename(segmentPath));

            const transcription = await this.openaiClient.audio.transcriptions.create({
                file: audioFile,
                model: 'whisper-1',
                store: false
            });

            const transcriptionText = transcription.text.trim();
            this.logger.info(`‚úÖ –°–µ–≥–º–µ–Ω—Ç ${segmentIndex} —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω: "${transcriptionText}"`);

            // –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —á–∞–Ω–∫–∞
            const chunkTimestamp = this.baseTimestampMs != null
                ? new Date(this.baseTimestampMs + (segmentIndex * SEGMENT_TIME * 1000))
                : new Date();
            const chunk = {
                segment_index: segmentIndex,
                id: `ch_${new ObjectId().toHexString()}`,
                text: transcriptionText,
                timestamp: chunkTimestamp,
                duration_seconds: SEGMENT_TIME
            };

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫ —Å—Ä–∞–∑—É –≤ MongoDB
            await this.db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
                mergeWithRuntimeFilter(
                    { _id: new ObjectId(this.messageId) },
                    { field: "runtime_tag" }
                ),
                {
                    $push: {
                        transcription_chunks: chunk
                    },
                    $set: {
                        transcribe_timestamp: Date.now(),
                        transcription_method: 'segmented',
                        last_chunk_update: new Date()
                    }
                }
            );

            this.logger.info(`üíæ –°–µ–≥–º–µ–Ω—Ç ${segmentIndex} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ MongoDB`);

            // –î–æ–±–∞–≤–ª—è–µ–º –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            this.transcriptionChunks.push(chunk);

            // –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
            try {
                fs.unlinkSync(segmentPath);
                this.logger.info(`üóëÔ∏è –°–µ–≥–º–µ–Ω—Ç ${segmentIndex} —É–¥–∞–ª–µ–Ω`);
            } catch (err) {
                this.logger.error(`–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞ ${segmentIndex}:`, err);
            }

        } catch (error) {
            this.logger.error(`‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ ${segmentIndex}:`, error);
            this.hasErrors = true;
            if (!this.error) {
                this.error = error;
            }

            // –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if (fs.existsSync(segmentPath)) {
                try {
                    const errorPath = segmentPath + '.error';
                    fs.renameSync(segmentPath, errorPath);
                    this.logger.info(`üîç –°–µ–≥–º–µ–Ω—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: ${errorPath}`);
                } catch (renameErr) {
                    this.logger.error('–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è:', renameErr);
                }
            }
        }
    }

    async saveTranscriptionChunks() {
        try {
            this.logger.info('üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–±–æ—Ä–∫—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤...');

            // –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏–∑ MongoDB –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            const messageData = await this.db.collection(constants.collections.VOICE_BOT_MESSAGES).findOne(
                mergeWithRuntimeFilter(
                    { _id: new ObjectId(this.messageId) },
                    { field: "runtime_tag" }
                ),
                { projection: { transcription_chunks: 1 } }
            );

            if (!messageData || !messageData.transcription_chunks) {
                this.logger.warn('–ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ MongoDB, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ');
                messageData.transcription_chunks = this.transcriptionChunks;
            }

            // –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É —Å–µ–≥–º–µ–Ω—Ç–∞
            const sortedChunks = messageData.transcription_chunks.sort((a, b) => a.segment_index - b.segment_index);

            // –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
            const fullTranscription = sortedChunks
                .map(chunk => chunk.text)
                .filter(text => text && text.trim()) // –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
                .join(' ');

            this.logger.info(`üìù –°–æ–±—Ä–∞–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∏–∑ ${sortedChunks.length} —Å–µ–≥–º–µ–Ω—Ç–æ–≤`);

            const baseSet = {
                transcription_text: fullTranscription,
                transcription_chunks: sortedChunks, // –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏
                transcription_method: 'segmented',
                transcribe_timestamp: Date.now(),
                total_segments: sortedChunks.length
            };

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏ –æ—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é
            const updatePayload = this.hasErrors
                ? {
                    $set: {
                        ...baseSet,
                        is_transcribed: false,
                        transcription_error: 'segment_transcription_failed',
                        error_message: getErrorMessage(this.error),
                        error_timestamp: new Date()
                    },
                    $unset: {
                        last_chunk_update: 1 // –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–ª–µ
                    }
                }
                : {
                    $set: {
                        ...baseSet,
                        is_transcribed: true,
                        transcription_completed_at: new Date()
                    },
                    $unset: {
                        last_chunk_update: 1 // –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–ª–µ
                    }
                };

            await this.db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
                mergeWithRuntimeFilter(
                    { _id: new ObjectId(this.messageId) },
                    { field: "runtime_tag" }
                ),
                updatePayload
            );

            this.logger.info(`‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: ${sortedChunks.length} —Å–µ–≥–º–µ–Ω—Ç–æ–≤, ${fullTranscription.length} —Å–∏–º–≤–æ–ª–æ–≤`);

            // –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            this.transcriptionChunks = sortedChunks;

        } catch (error) {
            this.logger.error('‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å–±–æ—Ä–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏:', error);

            // –ü–æ–ø—ã—Ç–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            try {
                const fallbackTranscription = this.transcriptionChunks
                    .sort((a, b) => a.segment_index - b.segment_index)
                    .map(chunk => chunk.text)
                    .filter(text => text && text.trim())
                    .join(' ');

                const fallbackSet = {
                    transcription_text: fallbackTranscription,
                    transcription_chunks: this.transcriptionChunks,
                    transcription_method: 'segmented_fallback',
                    transcribe_timestamp: Date.now()
                };

                await this.db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
                    mergeWithRuntimeFilter(
                        { _id: new ObjectId(this.messageId) },
                        { field: "runtime_tag" }
                    ),
                    {
                        $set: this.hasErrors
                            ? {
                                ...fallbackSet,
                                is_transcribed: false,
                                transcription_error: 'segment_transcription_failed',
                                error_message: getErrorMessage(this.error),
                                error_timestamp: new Date()
                            }
                            : {
                                ...fallbackSet,
                                is_transcribed: true,
                                transcription_completed_at: new Date()
                            }
                    }
                );

                this.logger.info('üíæ –†–µ–∑–µ—Ä–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ');
            } catch (fallbackError) {
                this.logger.error('‚ùå –û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:', fallbackError);
                throw error;
            }
        }
    }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω—É–∂–Ω–∞ –ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
async function shouldUseSegmentation(duration, fileLink, logger) {
    try {
        const DIRECT_PROCESSING_MAX_DURATION = 5 * 60; // 5 –º–∏–Ω—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        const MAX_FILE_SIZE_FOR_DIRECT = 20 * 1024 * 1024; // 20 –ú–ë (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–µ–¥–µ–ª –¥–ª—è OpenAI 25 –ú–ë)

        const fileLinkStr = fileLink?.toString ? fileLink.toString() : String(fileLink || "");

        logger.info(`–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: ${duration} —Å–µ–∫—É–Ω–¥ (${Math.round(duration / 60 * 100) / 100} –º–∏–Ω—É—Ç)`);

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –æ–Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞
        let needSegmentationByDuration = false;
        if (duration && duration > 0) {
            needSegmentationByDuration = duration > DIRECT_PROCESSING_MAX_DURATION;
            logger.info(`–ü–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: ${needSegmentationByDuration ? '–Ω—É–∂–Ω–∞' : '–Ω–µ –Ω—É–∂–Ω–∞'} —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è`);
        }

        // –í–°–ï–ì–î–ê –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        logger.info('–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞...');

        try {
            let contentLength = 0;

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ fileLink –ª–æ–∫–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º –∏–ª–∏ URL
            if (fileLinkStr.startsWith('http://') || fileLinkStr.startsWith('https://')) {
                // –î–ª—è HTTP URL –∏—Å–ø–æ–ª—å–∑—É–µ–º HEAD –∑–∞–ø—Ä–æ—Å
                const response = await axios.head(fileLinkStr);
                contentLength = parseInt(response.headers['content-length'] || '0');
            } else {
                // –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º fs.stat
                const fs = require('fs');
                const stats = fs.statSync(fileLinkStr);
                contentLength = stats.size;
            }

            logger.info(`–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: ${contentLength} –±–∞–π—Ç (${Math.round(contentLength / 1024 / 1024 * 100) / 100} MB)`);

            const needSegmentationBySize = contentLength > MAX_FILE_SIZE_FOR_DIRECT;
            logger.info(`–ü–æ —Ä–∞–∑–º–µ—Ä—É: ${needSegmentationBySize ? '–Ω—É–∂–Ω–∞' : '–Ω–µ –Ω—É–∂–Ω–∞'} —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è`);

            // –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω—É–∂–Ω–∞ –µ—Å–ª–∏ –õ–Æ–ë–û–ï –∏–∑ —É—Å–ª–æ–≤–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
            return needSegmentationByDuration || needSegmentationBySize;
        } catch (sizeError) {
            logger.warn('–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞:', sizeError.message);
            // –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            // –∏–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            if (duration && duration > 0) return needSegmentationByDuration;
            return true;
        }

    } catch (error) {
        logger.warn('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é:', error.message);
        return true; // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    }
}

const resolveDurationFromFileIfNeeded = async ({ message, fileLink, logger }) => {
    const initialDuration = resolveMessageDurationSeconds({ message, chunks: message?.transcription_chunks });
    if (initialDuration != null) return initialDuration;

    if (!fileLink) return null;

    try {
        const probedDuration = await getAudioDuration(fileLink.toString());
        if (Number.isFinite(probedDuration) && probedDuration > 0) {
            logger.info(`Resolved audio duration via ffprobe: ${probedDuration} seconds`);
            return probedDuration;
        }
    } catch (error) {
        logger.warn(`Could not resolve audio duration via ffprobe: ${error?.message || error}`);
    }

    return null;
};

const job_handler = async (job_data, queues, apis) => {
    const { tgbot, openaiClient, db, logger } = apis;
    /*
        job_data = {
                message_db_id: message_op_res.insertedId.toString(),
                message:{
                    file_id: ctx.message.voice.file_id,
                    chat_id: ctx.message.chat.id,
                    message_id: ctx.message.message_id,
                    message_timestamp: ctx.message.date,
                    duration: ctx.message.voice.duration,
                    timestamp: Date.now(),
                },
                message_context: [], // This is an empty array because we are not processing any previous messages in this job
                session_id: session._id,
                chat_id: message.chat_id,
        }
    */
    logger.info(`Transcribing voice message for chat_id: ${job_data.chat_id}, session_id: ${job_data.session_id}`);
    const { chat_id, session_id, message, message_context } = job_data;
    const messageObjectId = new ObjectId(job_data.message_db_id);
    const sessionObjectId = new ObjectId(session_id);
    const runtimeScopedMessageQuery = mergeWithRuntimeFilter(
        { _id: messageObjectId },
        { field: "runtime_tag" }
    );
    const runtimeScopedSessionQuery = mergeWithRuntimeFilter(
        { _id: sessionObjectId, is_deleted: { $ne: true } },
        { field: "runtime_tag" }
    );

    const msgRecord = await db.collection(constants.collections.VOICE_BOT_MESSAGES).findOne(
        runtimeScopedMessageQuery,
        { projection: { transcribe_attempts: 1, transcription_retry_reason: 1, session_id: 1, runtime_tag: 1 } }
    );
    if (!msgRecord || !recordMatchesRuntime(msgRecord, { field: "runtime_tag" })) {
        logger.warn(`Skipping transcribe for message ${job_data.message_db_id}: runtime mismatch or message not found [runtime=${constants.RUNTIME_TAG}]`);
        return;
    }
    if (msgRecord.session_id && msgRecord.session_id.toString() !== sessionObjectId.toString()) {
        logger.warn(`Skipping transcribe for message ${job_data.message_db_id}: session mismatch ${msgRecord.session_id} != ${sessionObjectId} [runtime=${constants.RUNTIME_TAG}]`);
        return;
    }
    const sessionRecord = await db.collection(constants.collections.VOICE_BOT_SESSIONS).findOne(
        runtimeScopedSessionQuery,
        { projection: { _id: 1, runtime_tag: 1 } }
    );
    if (!sessionRecord || !recordMatchesRuntime(sessionRecord, { field: "runtime_tag" })) {
        logger.warn(`Skipping transcribe for message ${job_data.message_db_id}: session runtime mismatch or not found [runtime=${constants.RUNTIME_TAG}]`);
        return;
    }
    const shouldSkipHardLimit = _.get(msgRecord, "transcription_retry_reason") === INSUFFICIENT_QUOTA_RETRY;
    const nextAttempts = (msgRecord && msgRecord.transcribe_attempts ? msgRecord.transcribe_attempts : 0) + 1;
    const attempts = nextAttempts;
    const now = Date.now();
    const nextAttemptAt = now + getRetryDelayMs(attempts);

    await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
        runtimeScopedMessageQuery,
        { $set: { transcribe_attempts: attempts } }
    );

    const markTranscriptionError = async ({
        error,
        code,
        transcription_text,
        transcription_chunks,
        isQuotaRetryable = false,
        skipRetrySchedule = false,
        filePath = null,
    }) => {
        const error_message = getErrorMessage(error);
        const resolvedCode = isQuotaRetryable ? (normalizeErrorCode(error) || INSUFFICIENT_QUOTA_RETRY) : code;
        const messageUpdate = {
            is_transcribed: false,
            transcription_error: resolvedCode,
            error_message: error_message,
            error_timestamp: new Date(),
            transcribe_timestamp: Date.now(),
            transcribe_attempts: attempts,
            transcription_error_context: getTranscriptionErrorContext({
                openaiClient,
                filePath,
                extra: {
                    error_code: resolvedCode,
                }
            }),
        };
        if (!skipRetrySchedule) {
            messageUpdate.transcription_next_attempt_at = new Date(nextAttemptAt);
        }
        if (isQuotaRetryable) {
            messageUpdate.to_transcribe = true;
            messageUpdate.transcription_retry_reason = INSUFFICIENT_QUOTA_RETRY;
        } else {
            messageUpdate.to_transcribe = false;
        }

        if (typeof transcription_text === "string") {
            messageUpdate.transcription_text = transcription_text;
        }
        if (Array.isArray(transcription_chunks)) {
            messageUpdate.transcription_chunks = transcription_chunks;
        }

        const messageUpdatePayload = { $set: messageUpdate };
        if (skipRetrySchedule) {
            messageUpdatePayload.$unset = {
                transcription_next_attempt_at: 1,
                transcription_retry_reason: 1,
            };
        } else if (!isQuotaRetryable) {
            messageUpdatePayload.$unset = {
                transcription_retry_reason: 1,
            };
        }

        await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
            runtimeScopedMessageQuery,
            messageUpdatePayload
        );

        await db.collection(constants.collections.VOICE_BOT_SESSIONS).updateOne(
            runtimeScopedSessionQuery,
            {
                $set: isQuotaRetryable
                    ? {
                        is_corrupted: false,
                        error_source: "transcription",
                        transcription_error: resolvedCode,
                        error_message: `OpenAI quota limit reached. Will resume automatically after payment restoration.`,
                        error_timestamp: new Date(),
                        error_message_id: job_data.message_db_id.toString(),
                        transcription_error_context: getTranscriptionErrorContext({
                            openaiClient,
                            filePath,
                            extra: {
                                error_code: resolvedCode,
                            }
                        }),
                    }
                    : {
                        is_corrupted: true,
                        error_source: "transcription",
                        transcription_error: resolvedCode,
                        error_message: error_message,
                        error_timestamp: new Date(),
                        error_message_id: job_data.message_db_id.toString(),
                        transcription_error_context: getTranscriptionErrorContext({
                            openaiClient,
                            filePath,
                            extra: {
                                error_code: resolvedCode,
                            }
                        }),
                    }
            }
        );

        await send_session_update_event(queues, session_id.toString(), db);
    };

    const clearQuotaRetryState = async () => {
        await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
            runtimeScopedMessageQuery,
            {
                $unset: {
                    transcription_error: 1,
                    error_message: 1,
                    transcription_error_context: 1,
                    error_timestamp: 1,
                    transcription_retry_reason: 1,
                    transcription_next_attempt_at: 1
                },
                $set: {
                    transcribe_attempts: 0,
                    to_transcribe: false,
                }
            }
        );

        await db.collection(constants.collections.VOICE_BOT_SESSIONS).updateOne(
            runtimeScopedSessionQuery,
            {
                $unset: {
                    error_source: 1,
                    transcription_error: 1,
                    transcription_error_context: 1,
                    error_message: 1,
                    error_timestamp: 1,
                    error_message_id: 1,
                },
                $set: {
                    is_corrupted: false,
                }
            }
        );
    };

    if (attempts > HARD_MAX_TRANSCRIBE_ATTEMPTS && !shouldSkipHardLimit) {
        logger.error(`Message ${job_data.message_db_id} has exceeded maximum transcription attempts. Marking as failed.`);
        await markTranscriptionError({
            error: "Message has exceeded maximum transcription attempts.",
            code: "max_attempts_exceeded",
            isQuotaRetryable: false,
            skipRetrySchedule: true,
        });
        return; // Stop processing
    }
    if (attempts > HARD_MAX_TRANSCRIBE_ATTEMPTS && shouldSkipHardLimit) {
        logger.warn(`Message ${job_data.message_db_id} reached hard attempt limit but has quota-blocked retry state; keeping open for retry.`);
    }

    // used for get file link from Telegram
    const file_id = message.file_id;

    // used for unique identification of voice file over all sessions and messages
    const file_unique_id = message.file_unique_id;

    // search in db if message with this file_id already exists and transcribed
    const existingMessage = await db.collection(constants.collections.VOICE_BOT_MESSAGES).findOne(
        mergeWithRuntimeFilter(
            {
                file_unique_id: { $ne: null },
                file_unique_id: file_unique_id,
                is_transcribed: true,
                transcribe_timestamp: Date.now()
            },
            { field: "runtime_tag" }
        )
    );

    let transcription_text = null;
    let transcription_chunks = [];
    let transcription_raw = null;

    if (existingMessage) {
        logger.info("Found existing transcribed message for file_id (file_unique_id):", file_id, file_unique_id);
        transcription_text = existingMessage.transcription_text;
        transcription_chunks = existingMessage.transcription_chunks || [];
        transcription_raw = existingMessage.transcription_raw || null;
    } else {
        let fileLink;
        let resolvedDurationSeconds = resolveMessageDurationSeconds({ message, chunks: null });

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏—è
        const sourceType = message.source_type || constants.voice_message_sources.TELEGRAM;

        if (sourceType === constants.voice_message_sources.TELEGRAM) {
            logger.info("Getting file link from Telegram for voice file_id (file_unique_id):", file_id, file_unique_id);

            try {
                fileLink = (await tgbot.telegram.getFileLink(file_id)).toString();
                logger.info("Got file link:", maskTelegramFileLink(fileLink));
            } catch (error) {
                if (error.message && error.message.includes('file is too big')) {
                    logger.error("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ Telegram API:", error.message);

                    // –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –ø—Ä–æ–±–ª–µ–º–µ
                    await tgbot.telegram.sendMessage(
                        message.chat_id,
                        "‚ùå –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–¥–æ 20 –ú–ë).",
                        { reply_to_message_id: message.message_id }
                    );

                    // –û—Ç–º–µ—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å –æ—à–∏–±–∫–æ–π
                    await markTranscriptionError({
                        error,
                        code: "file_too_big",
                        transcription_text: "[–û–®–ò–ë–ö–ê: –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏]"
                    });
                    try {
                        // –°—Ç–∞–≤–∏–º —Ä–µ–∞–∫—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ —Ç–æ–ª—å–∫–æ –¥–ª—è Telegram —Å–æ–æ–±—â–µ–Ω–∏–π
                        await tgbot.telegram.setMessageReaction(message.chat_id, message.message_id, [{ type: "emoji", emoji: "‚ùå" }]);
                    } catch (reactionError) {
                        logger.error(`Error setting reaction for message ${message._id}: ${reactionError.message}`);
                    }
                    return; // –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                } else {
                    // –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∫–∞–∫ –æ—à–∏–±–æ—á–Ω—É—é
                    await markTranscriptionError({
                        error,
                        code: "transcription_failed"
                    });
                    return;
                }
            }
        } else if (sourceType === constants.voice_message_sources.WEB) {
            let rawPath = message.file_path;
            if (!rawPath && job_data?.message_db_id) {
                const messageRecord = await db
                    .collection(constants.collections.VOICE_BOT_MESSAGES)
                    .findOne(
                        runtimeScopedMessageQuery,
                        { projection: { file_path: 1 } }
                    );
                rawPath = messageRecord?.file_path;
                if (rawPath) {
                    logger.info("Resolved web upload file path from DB:", rawPath);
                }
            }
            const resolvedPath = rawPath
                ? (path.isAbsolute(rawPath) ? rawPath : path.resolve(__dirname, '..', '..', rawPath))
                : null;
            logger.info("Using local file path for web upload:", resolvedPath || rawPath);
            if (!resolvedPath || !fs.existsSync(resolvedPath)) {
                await markTranscriptionError({
                    error: `Web upload file not found: ${resolvedPath || rawPath}`,
                    code: "file_not_found",
                    filePath: resolvedPath || rawPath,
                });
                return;
            }
            fileLink = resolvedPath; // –î–ª—è –≤–µ–±-–∑–∞–≥—Ä—É–∑–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
        } else {
            await markTranscriptionError({
                error: `Unknown source type: ${sourceType}`,
                code: "transcription_failed"
            });
            return;
        }

        resolvedDurationSeconds = await resolveDurationFromFileIfNeeded({ message, fileLink, logger });
        if (resolvedDurationSeconds != null && (!Number.isFinite(Number(message.duration)) || Number(message.duration) <= 0)) {
            message.duration = resolvedDurationSeconds;
            await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
                runtimeScopedMessageQuery,
                {
                    $set: {
                        duration: resolvedDurationSeconds,
                        "file_metadata.duration": resolvedDurationSeconds,
                    }
                }
            );
        }

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        const useSegmentation = await shouldUseSegmentation(resolvedDurationSeconds || 0, fileLink, logger);

        if (useSegmentation) {
            logger.info("üé¨ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞");

            // –û—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –æ—Ç —Å—Ç–∞—Ä—ã—Ö —á–∞–Ω–∫–æ–≤
            cleanChunksFolder();

            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ —á–∞–Ω–∫–æ–≤ –≤ MongoDB
            await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
                runtimeScopedMessageQuery,
                {
                    $set: {
                        transcription_chunks: [],
                        transcription_method: 'segmented',
                        transcription_started_at: new Date(),
                        transcribe_timestamp: Date.now(),
                        is_transcribed: false
                    }
                }
            );

            // –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            const processor = new VoiceBotSegmentProcessor(
                session_id.toString(),
                job_data.message_db_id,
                db,
                logger,
                openaiClient,
                Number(message?.message_timestamp) ? Number(message.message_timestamp) * 1000 : null
            );

                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ FFmpeg —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
                let result;
                try {
                    result = await processor.processStreamWithSegments(fileLink);
                } catch (error) {
                    await markTranscriptionError({
                        error,
                        code: "transcription_failed",
                        isQuotaRetryable: isQuotaError(error)
                    });
                    return;
                }

            transcription_text = processor.transcriptionChunks
                .map(chunk => chunk.text)
                .join(' ');
            transcription_chunks = processor.transcriptionChunks;
            transcription_raw = {
                provider: 'openai',
                model: 'whisper-1',
                response_format: 'text',
                segmented: true,
                segments: (transcription_chunks || []).map((chunk) => ({
                    segment_index: chunk?.segment_index ?? null,
                    id: chunk?.id || null,
                    text: chunk?.text || ''
                }))
            };

            logger.info(`‚úÖ –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: ${result.totalSegments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤`);
            if (processor.hasErrors) {
                logger.error('‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:', processor.error);
                await markTranscriptionError({
                    error: processor.error || "Segment transcription failed",
                    code: "segment_transcription_failed",
                    transcription_text: transcription_text,
                    transcription_chunks: transcription_chunks,
                    isQuotaRetryable: isQuotaError(processor.error),
                    filePath: fileLink,
                });
                return;
            }
        } else {
            logger.info("üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞");

            try {
                logger.info("Loading audio file...");
                const audioBuffer = await getAudioBuffer(message, tgbot, logger);

                logger.info("Loaded audio file, size:", audioBuffer.length);

                // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
                const type = await fileType.fromBuffer(audioBuffer);
                logger.info("Detected file type:", type);

                // –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
                let ext;
                // –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–∑—è—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ fileLink –∫–∞–∫ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ
                try {
                    const urlObj = new URL(fileLink.toString());
                    const pathname = urlObj.pathname;
                    const match = pathname.match(/\.([a-zA-Z0-9]+)$/);
                    if (match) {
                        ext = match[1];
                    }
                } catch (e) {
                    ext = 'mp3'; // fallback to mp3 if we can't parse the extension
                    logger.warn('Could not parse extension from fileLink:', e);
                }

                if (type && type.ext && ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm'].includes(type.ext)) {
                    ext = type.ext;
                } else if (type && type.ext === 'opus') {
                    ext = 'ogg';
                }

                const fileName = `speech-${message.chat_id}-${message.message_id}.${ext}`;

                logger.info("Uploading audio file to OpenAI for transcription...", fileName);
                const audioFile = await toFile(audioBuffer, fileName);

                logger.info("Requesting transcription from OpenAI...");
                const transcription = await openaiClient.audio.transcriptions.create({
                    file: audioFile,
                    model: 'whisper-1',
                });

                logger.info("Received transcription from OpenAI.");
                transcription_text = transcription.text;
                transcription_raw = transcription;

                // –î–ª—è –ø—Ä—è–º–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–∑–¥–∞–µ–º –æ–¥–∏–Ω —á–∞–Ω–∫
                transcription_chunks = [{
                    segment_index: 0,
                    id: `ch_${new ObjectId().toHexString()}`,
                    text: transcription_text,
                    timestamp: Number(message?.message_timestamp)
                        ? new Date(Number(message.message_timestamp) * 1000)
                        : new Date(),
                    duration_seconds: resolvedDurationSeconds || 0
                }];
            } catch (error) {
                const apiKey = openaiClient?.apiKey || process.env.OPENAI_API_KEY || "";
                const maskedKey = apiKey.match(/^sk-([a-zA-Z0-9]{4})[a-zA-Z0-9]+([a-zA-Z0-9]{4})$/)
                    ? `sk-${RegExp.$1}...${RegExp.$2}`
                    : 'sk-****';
                logger.error(`Error when transcribing ${message.message_id} [OpenAI key: ${maskedKey}]`);

                await markTranscriptionError({
                    error,
                    code: "transcription_failed",
                    isQuotaRetryable: isQuotaError(error),
                    filePath: fileLink,
                });
                return;
            }
        }
    }

    await clearQuotaRetryState();

    const canonicalDurationSeconds = resolveMessageDurationSeconds({ message, chunks: transcription_chunks });
    const timeline = buildSegmentsFromChunks({
        chunks: transcription_chunks,
        messageDurationSeconds: canonicalDurationSeconds,
        fallbackTimestampMs: Number(message?.message_timestamp)
            ? Number(message.message_timestamp) * 1000
            : Date.now(),
    });

    await db.collection(constants.collections.VOICE_BOT_MESSAGES).updateOne(
        runtimeScopedMessageQuery,
        {
            $set: {
                transcribe_timestamp: Date.now(),
                transcription_text: transcription_text,
                task: 'transcribe',
                text: transcription_text,
                transcription_raw: transcription_raw || {
                    provider: 'openai',
                    model: 'whisper-1',
                    segmented: transcription_chunks.length > 1,
                    text: transcription_text
                },
                transcription: {
                    schema_version: 1,
                    provider: 'openai',
                    model: 'whisper-1',
                    task: 'transcribe',
                    duration_seconds: canonicalDurationSeconds || null,
                    text: transcription_text,
                    segments: timeline.segments.map((segment) => ({
                        id: segment.id || `ch_${new ObjectId().toHexString()}`,
                        source_segment_id: null,
                        start: segment.start,
                        end: segment.end,
                        speaker: segment.speaker || null,
                        text: segment.text || '',
                        is_deleted: Boolean(segment.is_deleted)
                    })),
                    usage: null
                },
                transcription_chunks: transcription_chunks,
                is_transcribed: true,
                transcription_method: transcription_chunks.length > 1 ? 'segmented' : 'direct',
                transcribe_attempts: 0,
                to_transcribe: false
            }
        }
    );

    // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    await send_message_update_event(queues, { _id: session_id }, job_data.message_db_id, db);

    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∞–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è Telegram —Å–æ–æ–±—â–µ–Ω–∏–π
    const sourceType = message.source_type || constants.voice_message_sources.TELEGRAM;
    if (sourceType === constants.voice_message_sources.TELEGRAM) {
        try {
            await tgbot.telegram.setMessageReaction(message.chat_id, message.message_id, [{ type: "emoji", emoji: "‚úç" }]);
        } catch (error) {
            logger.error(`Error setting reaction for message ${message._id}: ${error.message}`);
        }
    }
}

module.exports = job_handler;
